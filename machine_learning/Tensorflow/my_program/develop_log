关于my_conv2d
===========================================================================
#{{{

	4/29
	今天我把my_conv2d写出来了。我的实现结果和TF的效果完全一样。
	卷积算法其实一共是三层，6个for循环
	1）x_col 和x_row是第一层，卷积结果的result 的二维矩阵size得和x一样[x_col, x_row]
	2）每一次，用W，就是卷积内核，去覆盖x的那一组数据，所以有了w_in_col 和w_in_row那两个for循环。每次要生成一对x_pos_col 和x_pos_row。这里有个小问题，就是如果卷积内核超过x的边界了，就要放弃，所以才有了越界continue那两个判断
	3）具体到了每一个点了，这个点的数据量是w_out_size，这就是为什么result_shape = [x_col, x_row, w_out_size]。
	x 和W的in_size必须得一样,具体到了这个点的运算了，其实就是两个二维矩阵的乘法。x每个点的数据[1][w_in_size] × w每个点的数据[w_in_size][w_out_size] = [1][w_out_size]
	然后这个[1][w_out_size] 的数据就变成了result[x_col, x_row][w_out_size]
	
	关于mid：
		用w去conv x_image,要保证w的正中心对准x的那个点，所以要算w_mid。理论上说w必须得是个正方形，我还没见过不是正方形的w。
		原实验的w_size是5,那它的mid就应该是2.我自己的实验里w_size是2,那我的mid就是0,即左上角。
		以此类推，如果w_size=3,mid=1，w正中心为[1][1]
				  如果w_size=4,mid=1，w正中心为[1][1]，这一点未获证实。我还没做过TF的conv2d实验测试过w_size=4
		那么我的算mid的方法为:
			w_mid = int(w_size / 2)
			w_mid_rem = w_size % 2
			如果w_size能整除2,就再给mid减个1
		
		算完了mid，为了把w的正中心对准x_image的对应点，就要用这个方法：
			x_pos_col = x_in_col - mid + w_in_col
			x_pos_row = x_in_row - mid + w_in_row
		只需要判断一下会不会过界就行了。

	关于其他操作：
		tf.nn.conv2d有几个选项:
			可以调节步长，我就是用的strides=[1, 1, 1, 1]
			padding='SAME' 代表着卷积完的图和原图一样大。还有个别的选项是边上加个边。
			我既然用的same方式，那就要在my_conv2d里有个越界判断，


#}}}

关于pool
===========================================================================
4/30
	可以这么理解： pooling 是用一个kernel罩在图上，取那个kernel所罩的图片上的点的最大值
	这里有两个重要的量，一个是kernel的size，可以认为kernel是方的。一个是step。具体在TF里就是两个配置：
		x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
	这个SAME就是不加边了。
	算法实现：
		1）先算好结果的大小，这个结果大小靠step和图片x的大小决定
		2）外层的两层for循环是结果的大小，不是x的大小，这里体现一个思想就是按step去生成结果
		3）每次，用那个kernel套住的x的那些点，有很多维（如例子里的pool1，每个点有32个float数，这就是32维）。每一维的最大值会成为结果的那个输出点的那维的值。
		4）所以，第三层的for循环应该是按out_size循环的，就是对应输出的那个点的每一维。
		5）确定维号以后，收集kernel套住的x的那些点的这一维的数据，放进一个数组里，最后取最大值。






4/30
	我的conv2d 和pool已经可以实现到原程序的pool2了，完全正确。后面就是fc1了，全连接层




